{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN for Mnist Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjOJC/Mk9W7e8F9XCp7s44",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/revs1/Simple_ML_notebooks-revs96/blob/master/GAN_for_Mnist_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA5K9iG6nSJj",
        "colab_type": "code",
        "outputId": "81dda96a-0d4e-4b83-a871-1e55bf1d99f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%tensorflow_version 1.14.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.14.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBMfjwyLnz4b",
        "colab_type": "code",
        "outputId": "2043d58b-3432-4fcc-a99d-2576d80a922a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "# importing the necessary libraries and the MNIST dataset \n",
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from tensorflow.examples.tutorials.mnist import input_data \n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\") \n",
        "\n",
        "# defining functions for the two networks. \n",
        "# Both the networks have two hidden layers \n",
        "# and an output layer which are densely or \n",
        "# fully connected layers defining the \n",
        "# Generator network function \n",
        "def generator(z, reuse = None): \n",
        "\twith tf.variable_scope('gen', reuse = reuse): \n",
        "\t\thidden1 = tf.layers.dense(inputs = z, units = 128, \n",
        "\t\t\t\t\t\t\tactivation = tf.nn.leaky_relu) \n",
        "\t\t\t\t\t\t\t\n",
        "\t\thidden2 = tf.layers.dense(inputs = hidden1, \n",
        "\t\tunits = 128, activation = tf.nn.leaky_relu) \n",
        "\t\t\t\n",
        "\t\toutput = tf.layers.dense(inputs = hidden2, \n",
        "\t\t\tunits = 784, activation = tf.nn.tanh) \n",
        "\t\t\n",
        "\t\treturn output \n",
        "\n",
        "# defining the Discriminator network function \n",
        "def discriminator(X, reuse = None): \n",
        "\twith tf.variable_scope('dis', reuse = reuse): \n",
        "\t\thidden1 = tf.layers.dense(inputs = X, units = 128, \n",
        "\t\t\t\t\t\t\tactivation = tf.nn.leaky_relu) \n",
        "\t\t\t\t\t\t\t\n",
        "\t\thidden2 = tf.layers.dense(inputs = hidden1, \n",
        "\t\t\tunits = 128, activation = tf.nn.leaky_relu) \n",
        "\t\t\t\t\n",
        "\t\tlogits = tf.layers.dense(hidden2, units = 1) \n",
        "\t\toutput = tf.sigmoid(logits) \n",
        "\t\t\n",
        "\t\treturn output, logits \n",
        "\n",
        "# creating placeholders for the outputs \n",
        "tf.reset_default_graph() \n",
        "\n",
        "real_images = tf.placeholder(tf.float32, shape =[None, 784]) \n",
        "z = tf.placeholder(tf.float32, shape =[None, 100]) \n",
        "\n",
        "G = generator(z) \n",
        "D_output_real, D_logits_real = discriminator(real_images) \n",
        "D_output_fake, D_logits_fake = discriminator(G, reuse = True) \n",
        "\n",
        "# defining the loss function \n",
        "def loss_func(logits_in, labels_in): \n",
        "\treturn tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits( \n",
        "\t\t\t\t\t\tlogits = logits_in, labels = labels_in)) \n",
        "\n",
        "# Smoothing for generalization \n",
        "D_real_loss = loss_func(D_logits_real, tf.ones_like(D_logits_real)*0.9) \n",
        "D_fake_loss = loss_func(D_logits_fake, tf.zeros_like(D_logits_real)) \n",
        "D_loss = D_real_loss + D_fake_loss \n",
        "\n",
        "G_loss = loss_func(D_logits_fake, tf.ones_like(D_logits_fake)) \n",
        "\n",
        "# defining the learning rate, batch size, \n",
        "# number of epochs and using the Adam optimizer \n",
        "lr = 0.001 # learning rate \n",
        "\n",
        "# Do this when multiple networks \n",
        "# interact with each other \n",
        "\n",
        "# returns all variables created(the two \n",
        "# variable scopes) and makes trainable true \n",
        "tvars = tf.trainable_variables() \n",
        "d_vars =[var for var in tvars if 'dis' in var.name] \n",
        "g_vars =[var for var in tvars if 'gen' in var.name] \n",
        "\n",
        "D_trainer = tf.train.AdamOptimizer(lr).minimize(D_loss, var_list = d_vars) \n",
        "G_trainer = tf.train.AdamOptimizer(lr).minimize(G_loss, var_list = g_vars) \n",
        "\n",
        "batch_size = 100 # batch size \n",
        "epochs = 500 # number of epochs. The higher the better the result \n",
        "init = tf.global_variables_initializer() \n",
        "\n",
        "# creating a session to train the networks \n",
        "samples =[] # generator examples \n",
        "\n",
        "with tf.Session() as sess: \n",
        "\tsess.run(init) \n",
        "\tfor epoch in range(epochs): \n",
        "\t\tnum_batches = mnist.train.num_examples//batch_size \n",
        "\t\t\n",
        "\t\tfor i in range(num_batches): \n",
        "\t\t\tbatch = mnist.train.next_batch(batch_size) \n",
        "\t\t\tbatch_images = batch[0].reshape((batch_size, 784)) \n",
        "\t\t\tbatch_images = batch_images * 2-1\n",
        "\t\t\tbatch_z = np.random.uniform(-1, 1, size =(batch_size, 100)) \n",
        "\t\t\t_= sess.run(D_trainer, feed_dict ={real_images:batch_images, z:batch_z}) \n",
        "\t\t\t_= sess.run(G_trainer, feed_dict ={z:batch_z}) \n",
        "\t\t\t\n",
        "\t\tprint(\"on epoch{}\".format(epoch)) \n",
        "\t\t\n",
        "\t\tsample_z = np.random.uniform(-1, 1, size =(1, 100)) \n",
        "\t\tgen_sample = sess.run(generator(z, reuse = True), \n",
        "\t\t\t\t\t\t\t\tfeed_dict ={z:sample_z}) \n",
        "\t\t\n",
        "\t\tsamples.append(gen_sample) \n",
        "\n",
        "# result after 0th epoch \n",
        "plt.imshow(samples[0].reshape(28, 28)) \n",
        "\n",
        "# result after 499th epoch \n",
        "plt.imshow(samples[49].reshape(28, 28)) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-32ddd7b92272>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From <ipython-input-2-32ddd7b92272>:16: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "on epoch0\n",
            "on epoch1\n",
            "on epoch2\n",
            "on epoch3\n",
            "on epoch4\n",
            "on epoch5\n",
            "on epoch6\n",
            "on epoch7\n",
            "on epoch8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeZbRuq9rdjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}